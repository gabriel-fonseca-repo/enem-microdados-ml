{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentação de modelos e configurações para a tarefa de classificação.\n",
    "\n",
    "##### Alunos:\n",
    "- Gabriel Fonseca (2111066)\n",
    "- Yasmim Santos (2116925)\n",
    "- Alejandro Elias (2111189)\n",
    "- Pedro Lucas (2111131)\n",
    "\n",
    "Base de dados escolhida - Exame Nacional do Ensino Médio (Enem): https://basedosdados.org/dataset/3e9c8804-c31c-4f48-9a45-d67f1c21a859"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as dependências:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo e visualizando os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_inscricao</th>\n",
       "      <th>ensino</th>\n",
       "      <th>nota_ciencias_natureza</th>\n",
       "      <th>nota_ciencias_humanas</th>\n",
       "      <th>nota_linguagens_codigos</th>\n",
       "      <th>nota_matematica</th>\n",
       "      <th>nota_redacao</th>\n",
       "      <th>q_formacao_pai</th>\n",
       "      <th>q_formacao_mae</th>\n",
       "      <th>q_renda_familia</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150001892848</td>\n",
       "      <td>3</td>\n",
       "      <td>366.8</td>\n",
       "      <td>436.9</td>\n",
       "      <td>374.2</td>\n",
       "      <td>331.4</td>\n",
       "      <td>380.0</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150002421428</td>\n",
       "      <td>1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>636.9</td>\n",
       "      <td>552.0</td>\n",
       "      <td>549.2</td>\n",
       "      <td>760.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150004396764</td>\n",
       "      <td>1</td>\n",
       "      <td>470.8</td>\n",
       "      <td>519.3</td>\n",
       "      <td>465.2</td>\n",
       "      <td>350.8</td>\n",
       "      <td>580.0</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150001657786</td>\n",
       "      <td>1</td>\n",
       "      <td>492.6</td>\n",
       "      <td>641.2</td>\n",
       "      <td>553.2</td>\n",
       "      <td>649.5</td>\n",
       "      <td>840.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150005415838</td>\n",
       "      <td>1</td>\n",
       "      <td>473.3</td>\n",
       "      <td>533.4</td>\n",
       "      <td>443.3</td>\n",
       "      <td>447.4</td>\n",
       "      <td>400.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357268</th>\n",
       "      <td>210054596750</td>\n",
       "      <td>1</td>\n",
       "      <td>450.6</td>\n",
       "      <td>403.1</td>\n",
       "      <td>443.3</td>\n",
       "      <td>479.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357269</th>\n",
       "      <td>210056286560</td>\n",
       "      <td>1</td>\n",
       "      <td>416.5</td>\n",
       "      <td>427.3</td>\n",
       "      <td>484.6</td>\n",
       "      <td>376.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357270</th>\n",
       "      <td>210057495281</td>\n",
       "      <td>1</td>\n",
       "      <td>462.1</td>\n",
       "      <td>421.7</td>\n",
       "      <td>432.1</td>\n",
       "      <td>530.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357271</th>\n",
       "      <td>210056812211</td>\n",
       "      <td>1</td>\n",
       "      <td>519.1</td>\n",
       "      <td>570.4</td>\n",
       "      <td>537.3</td>\n",
       "      <td>388.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357272</th>\n",
       "      <td>210054625226</td>\n",
       "      <td>1</td>\n",
       "      <td>467.2</td>\n",
       "      <td>421.9</td>\n",
       "      <td>399.1</td>\n",
       "      <td>443.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357273 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_inscricao  ensino  nota_ciencias_natureza  nota_ciencias_humanas  \\\n",
       "0       150001892848       3                   366.8                  436.9   \n",
       "1       150002421428       1                   512.0                  636.9   \n",
       "2       150004396764       1                   470.8                  519.3   \n",
       "3       150001657786       1                   492.6                  641.2   \n",
       "4       150005415838       1                   473.3                  533.4   \n",
       "...              ...     ...                     ...                    ...   \n",
       "357268  210054596750       1                   450.6                  403.1   \n",
       "357269  210056286560       1                   416.5                  427.3   \n",
       "357270  210057495281       1                   462.1                  421.7   \n",
       "357271  210056812211       1                   519.1                  570.4   \n",
       "357272  210054625226       1                   467.2                  421.9   \n",
       "\n",
       "        nota_linguagens_codigos  nota_matematica  nota_redacao q_formacao_pai  \\\n",
       "0                         374.2            331.4         380.0              B   \n",
       "1                         552.0            549.2         760.0              A   \n",
       "2                         465.2            350.8         580.0              B   \n",
       "3                         553.2            649.5         840.0              A   \n",
       "4                         443.3            447.4         400.0              A   \n",
       "...                         ...              ...           ...            ...   \n",
       "357268                    443.3            479.8           0.0              E   \n",
       "357269                    484.6            376.2           0.0              D   \n",
       "357270                    432.1            530.9           0.0              C   \n",
       "357271                    537.3            388.7           0.0              D   \n",
       "357272                    399.1            443.6           0.0              F   \n",
       "\n",
       "       q_formacao_mae q_renda_familia   ano  \n",
       "0                   A               C  2015  \n",
       "1                   A               C  2015  \n",
       "2                   A               B  2015  \n",
       "3                   A               A  2015  \n",
       "4                   A               A  2015  \n",
       "...               ...             ...   ...  \n",
       "357268              E               B  2022  \n",
       "357269              D               A  2022  \n",
       "357270              D               B  2022  \n",
       "357271              H               B  2022  \n",
       "357272              G               H  2022  \n",
       "\n",
       "[357273 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enem = pd.read_csv(\n",
    "    f\"../data/out/enem-dados-tratados.csv\",\n",
    "    dtype={\n",
    "        \"id_inscricao\": np.int64,\n",
    "        \"ensino\": int,\n",
    "        \"nota_ciencias_natureza\": float,\n",
    "        \"nota_ciencias_humanas\": float,\n",
    "        \"nota_linguagens_codigos\": float,\n",
    "        \"nota_matematica\": float,\n",
    "        \"nota_redacao\": float,\n",
    "        \"q_formacao_pai\": str,\n",
    "        \"q_formacao_mae\": str,\n",
    "        \"q_renda_familia\": str,\n",
    "    },\n",
    ")\n",
    "\n",
    "df_enem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os dados para utilização no teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_inscricao</th>\n",
       "      <th>ensino</th>\n",
       "      <th>nota_ciencias_natureza</th>\n",
       "      <th>nota_ciencias_humanas</th>\n",
       "      <th>nota_linguagens_codigos</th>\n",
       "      <th>nota_matematica</th>\n",
       "      <th>nota_redacao</th>\n",
       "      <th>q_formacao_pai</th>\n",
       "      <th>q_formacao_mae</th>\n",
       "      <th>q_renda_familia</th>\n",
       "      <th>ano</th>\n",
       "      <th>nota_objetiva</th>\n",
       "      <th>nota_objetiva_scl</th>\n",
       "      <th>q_renda_familia_classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150001892848</td>\n",
       "      <td>3</td>\n",
       "      <td>366.8</td>\n",
       "      <td>436.9</td>\n",
       "      <td>374.2</td>\n",
       "      <td>331.4</td>\n",
       "      <td>380.0</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2015</td>\n",
       "      <td>377.325</td>\n",
       "      <td>0.293561</td>\n",
       "      <td>muito_baixa_renda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150002421428</td>\n",
       "      <td>1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>636.9</td>\n",
       "      <td>552.0</td>\n",
       "      <td>549.2</td>\n",
       "      <td>760.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2015</td>\n",
       "      <td>562.525</td>\n",
       "      <td>0.579518</td>\n",
       "      <td>muito_baixa_renda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150004396764</td>\n",
       "      <td>1</td>\n",
       "      <td>470.8</td>\n",
       "      <td>519.3</td>\n",
       "      <td>465.2</td>\n",
       "      <td>350.8</td>\n",
       "      <td>580.0</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>2015</td>\n",
       "      <td>451.525</td>\n",
       "      <td>0.408129</td>\n",
       "      <td>muito_baixa_renda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150001657786</td>\n",
       "      <td>1</td>\n",
       "      <td>492.6</td>\n",
       "      <td>641.2</td>\n",
       "      <td>553.2</td>\n",
       "      <td>649.5</td>\n",
       "      <td>840.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>2015</td>\n",
       "      <td>584.125</td>\n",
       "      <td>0.612870</td>\n",
       "      <td>nenhuma_renda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150005415838</td>\n",
       "      <td>1</td>\n",
       "      <td>473.3</td>\n",
       "      <td>533.4</td>\n",
       "      <td>443.3</td>\n",
       "      <td>447.4</td>\n",
       "      <td>400.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>2015</td>\n",
       "      <td>474.350</td>\n",
       "      <td>0.443372</td>\n",
       "      <td>nenhuma_renda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357268</th>\n",
       "      <td>210054596750</td>\n",
       "      <td>1</td>\n",
       "      <td>450.6</td>\n",
       "      <td>403.1</td>\n",
       "      <td>443.3</td>\n",
       "      <td>479.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>2022</td>\n",
       "      <td>444.200</td>\n",
       "      <td>0.396819</td>\n",
       "      <td>muito_baixa_renda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357269</th>\n",
       "      <td>210056286560</td>\n",
       "      <td>1</td>\n",
       "      <td>416.5</td>\n",
       "      <td>427.3</td>\n",
       "      <td>484.6</td>\n",
       "      <td>376.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "      <td>426.150</td>\n",
       "      <td>0.368949</td>\n",
       "      <td>nenhuma_renda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357270</th>\n",
       "      <td>210057495281</td>\n",
       "      <td>1</td>\n",
       "      <td>462.1</td>\n",
       "      <td>421.7</td>\n",
       "      <td>432.1</td>\n",
       "      <td>530.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>2022</td>\n",
       "      <td>461.700</td>\n",
       "      <td>0.423840</td>\n",
       "      <td>muito_baixa_renda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357271</th>\n",
       "      <td>210056812211</td>\n",
       "      <td>1</td>\n",
       "      <td>519.1</td>\n",
       "      <td>570.4</td>\n",
       "      <td>537.3</td>\n",
       "      <td>388.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>2022</td>\n",
       "      <td>503.875</td>\n",
       "      <td>0.488960</td>\n",
       "      <td>muito_baixa_renda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357272</th>\n",
       "      <td>210054625226</td>\n",
       "      <td>1</td>\n",
       "      <td>467.2</td>\n",
       "      <td>421.9</td>\n",
       "      <td>399.1</td>\n",
       "      <td>443.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>2022</td>\n",
       "      <td>432.950</td>\n",
       "      <td>0.379449</td>\n",
       "      <td>baixa_renda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355666 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_inscricao  ensino  nota_ciencias_natureza  nota_ciencias_humanas  \\\n",
       "0       150001892848       3                   366.8                  436.9   \n",
       "1       150002421428       1                   512.0                  636.9   \n",
       "2       150004396764       1                   470.8                  519.3   \n",
       "3       150001657786       1                   492.6                  641.2   \n",
       "4       150005415838       1                   473.3                  533.4   \n",
       "...              ...     ...                     ...                    ...   \n",
       "357268  210054596750       1                   450.6                  403.1   \n",
       "357269  210056286560       1                   416.5                  427.3   \n",
       "357270  210057495281       1                   462.1                  421.7   \n",
       "357271  210056812211       1                   519.1                  570.4   \n",
       "357272  210054625226       1                   467.2                  421.9   \n",
       "\n",
       "        nota_linguagens_codigos  nota_matematica  nota_redacao q_formacao_pai  \\\n",
       "0                         374.2            331.4         380.0              B   \n",
       "1                         552.0            549.2         760.0              A   \n",
       "2                         465.2            350.8         580.0              B   \n",
       "3                         553.2            649.5         840.0              A   \n",
       "4                         443.3            447.4         400.0              A   \n",
       "...                         ...              ...           ...            ...   \n",
       "357268                    443.3            479.8           0.0              E   \n",
       "357269                    484.6            376.2           0.0              D   \n",
       "357270                    432.1            530.9           0.0              C   \n",
       "357271                    537.3            388.7           0.0              D   \n",
       "357272                    399.1            443.6           0.0              F   \n",
       "\n",
       "       q_formacao_mae q_renda_familia   ano  nota_objetiva  nota_objetiva_scl  \\\n",
       "0                   A               C  2015        377.325           0.293561   \n",
       "1                   A               C  2015        562.525           0.579518   \n",
       "2                   A               B  2015        451.525           0.408129   \n",
       "3                   A               A  2015        584.125           0.612870   \n",
       "4                   A               A  2015        474.350           0.443372   \n",
       "...               ...             ...   ...            ...                ...   \n",
       "357268              E               B  2022        444.200           0.396819   \n",
       "357269              D               A  2022        426.150           0.368949   \n",
       "357270              D               B  2022        461.700           0.423840   \n",
       "357271              H               B  2022        503.875           0.488960   \n",
       "357272              G               H  2022        432.950           0.379449   \n",
       "\n",
       "       q_renda_familia_classe  \n",
       "0           muito_baixa_renda  \n",
       "1           muito_baixa_renda  \n",
       "2           muito_baixa_renda  \n",
       "3               nenhuma_renda  \n",
       "4               nenhuma_renda  \n",
       "...                       ...  \n",
       "357268      muito_baixa_renda  \n",
       "357269          nenhuma_renda  \n",
       "357270      muito_baixa_renda  \n",
       "357271      muito_baixa_renda  \n",
       "357272            baixa_renda  \n",
       "\n",
       "[355666 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "\n",
    "df_enem = df_enem[df_enem[\"nota_ciencias_natureza\"] != 0.0]\n",
    "df_enem = df_enem[df_enem[\"nota_ciencias_humanas\"] != 0.0]\n",
    "\n",
    "df_enem[\"nota_objetiva\"] = (\n",
    "    df_enem[\"nota_ciencias_natureza\"]\n",
    "    + df_enem[\"nota_ciencias_humanas\"]\n",
    "    + df_enem[\"nota_linguagens_codigos\"]\n",
    "    + df_enem[\"nota_matematica\"]\n",
    ") / 4\n",
    "\n",
    "df_enem[\"nota_objetiva_scl\"] = mm_scaler.fit_transform(df_enem[[\"nota_objetiva\"]])\n",
    "\n",
    "map_grupo_renda = {\n",
    "    \"A\": \"nenhuma_renda\",\n",
    "    \"B\": \"muito_baixa_renda\",\n",
    "    \"C\": \"muito_baixa_renda\",\n",
    "    \"D\": \"muito_baixa_renda\",\n",
    "    \"E\": \"muito_baixa_renda\",\n",
    "    \"F\": \"baixa_renda\",\n",
    "    \"G\": \"baixa_renda\",\n",
    "    \"H\": \"baixa_renda\",\n",
    "    \"I\": \"baixa_renda\",\n",
    "    \"J\": \"media_renda\",\n",
    "    \"K\": \"media_renda\",\n",
    "    \"L\": \"media_renda\",\n",
    "    \"M\": \"media_renda\",\n",
    "    \"N\": \"alta_renda\",\n",
    "    \"O\": \"alta_renda\",\n",
    "    \"P\": \"alta_renda\",\n",
    "    \"Q\": \"alta_renda\"\n",
    "}\n",
    "\n",
    "df_enem[\"q_renda_familia_classe\"] = df_enem[\"q_renda_familia\"].map(map_grupo_renda)\n",
    "df_enem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.403883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.423686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.297614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.454605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.403883\n",
       "1  0.423686\n",
       "2  0.445881\n",
       "3  0.297614\n",
       "4  0.454605"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    \"nota_objetiva_scl\",\n",
    "]\n",
    "\n",
    "X = np.array(df_enem[features])\n",
    "Y = np.array(df_enem[\"q_renda_familia_classe\"])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, train_size=0.8, random_state=5487\n",
    ")\n",
    "\n",
    "X_train: np.ndarray = X_train\n",
    "Y_train: np.ndarray = Y_train\n",
    "X_test: np.ndarray = X_test\n",
    "Y_test: np.ndarray = Y_test\n",
    "\n",
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando o teste:\n",
    "##### Modelos selecionados:\n",
    "1. **Regressão Logística (`LogisticRegression`)**:\n",
    "2. **K-Nearest Neighbors (`KNeighborsClassifier`)**:\n",
    "3. **Support Vector Classifier (`SVC`)**:\n",
    "4. **Decision Tree Classifier (`DecisionTreeClassifier`)**:\n",
    "5. **Random Forest Classifier (`RandomForestClassifier`)**:\n",
    "6. **Gradient Boosting Classifier (`GradientBoostingClassifier`)**:\n",
    "7. **AdaBoost Classifier (`AdaBoostClassifier`)**:\n",
    "8. **Naive Bayes (`GaussianNB`, `MultinomialNB`, `BernoulliNB`)**:\n",
    "9. **Perceptron (`Perceptron`)**:\n",
    "10. **SGD Linear Classifier (`SGDClassifier`)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando o modelo LogisticRegression... [1/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "300 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1182, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.74631676 0.74819001 0.74555059 0.74793696        nan        nan\n",
      "        nan        nan 0.74631676 0.74819352 0.74555059 0.74791587\n",
      "        nan        nan        nan        nan 0.74631676 0.74819704\n",
      " 0.74555059 0.74791236        nan        nan        nan        nan\n",
      " 0.74641165 0.74821813 0.74636245 0.74819352        nan        nan\n",
      "        nan        nan 0.74641165 0.74820407 0.74636245 0.74819704\n",
      "        nan        nan        nan        nan 0.74641165 0.74820758\n",
      " 0.74636245 0.74819704        nan        nan        nan        nan\n",
      " 0.74639759 0.74821461 0.74638705 0.74820758        nan        nan\n",
      "        nan        nan 0.74640462 0.74821461 0.74638705 0.74819704\n",
      "        nan        nan        nan        nan 0.74640462 0.74821461\n",
      " 0.74638705 0.74821461        nan        nan        nan        nan\n",
      " 0.74641165 0.74821813 0.74639056 0.74823921        nan        nan\n",
      "        nan        nan 0.74639056 0.74821813 0.74639056 0.74821461\n",
      "        nan        nan        nan        nan 0.74640814 0.74821813\n",
      " 0.74639056 0.74820758        nan        nan        nan        nan\n",
      " 0.74640111 0.7482111  0.74639056 0.7482111         nan        nan\n",
      "        nan        nan 0.74640111 0.74821461 0.74639056 0.74821813\n",
      "        nan        nan        nan        nan 0.74640462 0.74821461\n",
      " 0.74639056 0.74820758        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando o modelo KNeighborsClassifier... [2/11]\n",
      "Avaliando o modelo DecisionTreeClassifier... [3/11]\n",
      "Avaliando o modelo RandomForestClassifier... [4/11]\n",
      "Avaliando o modelo GradientBoostingClassifier... [5/11]\n",
      "Avaliando o modelo AdaBoostClassifier... [6/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliando o modelo GaussianNB... [7/11]\n",
      "Avaliando o modelo MultinomialNB... [8/11]\n",
      "Avaliando o modelo BernoulliNB... [9/11]\n",
      "Avaliando o modelo Perceptron... [10/11]\n",
      "Avaliando o modelo SGDClassifier... [11/11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "600 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "360 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 915, in fit\n",
      "    self._more_validate_params()\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 153, in _more_validate_params\n",
      "    raise ValueError(\"eta0 must be > 0\")\n",
      "ValueError: eta0 must be > 0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'hinge', 'epsilon_insensitive', 'huber', 'perceptron', 'log_loss', 'squared_error', 'modified_huber', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\fonsecovizk\\Projetos\\enem-microdados-ml\\.env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.73775182 0.73817708 0.73819465\n",
      "        nan        nan        nan 0.74334696 0.74331886 0.74425723\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.73693996 0.73588559 0.73588559\n",
      "        nan        nan        nan 0.74341726 0.74234884 0.7411785\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.73588559 0.73588559 0.73588559\n",
      "        nan        nan        nan 0.73670448 0.73611755 0.73616676\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.73588559 0.73588559 0.73588559\n",
      "        nan        nan        nan 0.73588559 0.73588559 0.73588559\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Melhor pontuação</th>\n",
       "      <th>Melhores parâmetros</th>\n",
       "      <th>Resultado avaliação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.748239</td>\n",
       "      <td>{'C': 100, 'max_iter': 1000, 'penalty': 'l2', ...</td>\n",
       "      <td>0.749965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.743807</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 20, ...</td>\n",
       "      <td>0.746675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.746623</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_leaf': 5, 'min_...</td>\n",
       "      <td>0.749431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.747589</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.750077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.750021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.748179</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 50}</td>\n",
       "      <td>0.749613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.744988</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.747350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.735886</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.737931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.735886</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.737931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.739660</td>\n",
       "      <td>{'alpha': 0.0001, 'max_iter': 1000, 'penalty':...</td>\n",
       "      <td>0.562038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.744257</td>\n",
       "      <td>{'alpha': 0.0001, 'learning_rate': 'optimal', ...</td>\n",
       "      <td>0.743358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Modelo  Melhor pontuação  \\\n",
       "0           LogisticRegression          0.748239   \n",
       "1         KNeighborsClassifier          0.743807   \n",
       "2       DecisionTreeClassifier          0.746623   \n",
       "3       RandomForestClassifier          0.747589   \n",
       "4   GradientBoostingClassifier          0.748148   \n",
       "5           AdaBoostClassifier          0.748179   \n",
       "6                   GaussianNB          0.744988   \n",
       "7                MultinomialNB          0.735886   \n",
       "8                  BernoulliNB          0.735886   \n",
       "9                   Perceptron          0.739660   \n",
       "10               SGDClassifier          0.744257   \n",
       "\n",
       "                                  Melhores parâmetros  Resultado avaliação  \n",
       "0   {'C': 100, 'max_iter': 1000, 'penalty': 'l2', ...             0.749965  \n",
       "1   {'algorithm': 'ball_tree', 'n_neighbors': 20, ...             0.746675  \n",
       "2   {'max_depth': 10, 'min_samples_leaf': 5, 'min_...             0.749431  \n",
       "3   {'max_depth': 10, 'max_features': 'sqrt', 'n_e...             0.750077  \n",
       "4   {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...             0.750021  \n",
       "5          {'learning_rate': 0.1, 'n_estimators': 50}             0.749613  \n",
       "6                                                  {}             0.747350  \n",
       "7                                     {'alpha': 0.01}             0.737931  \n",
       "8                                     {'alpha': 0.01}             0.737931  \n",
       "9   {'alpha': 0.0001, 'max_iter': 1000, 'penalty':...             0.562038  \n",
       "10  {'alpha': 0.0001, 'learning_rate': 'optimal', ...             0.743358  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "models_params = {\n",
    "    LogisticRegression(): {\n",
    "        \"C\": [0.1, 1, 10, 100, 1000],\n",
    "        \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "        \"solver\": [\"liblinear\", \"saga\"],\n",
    "        \"max_iter\": [1000, 2000, 3000],\n",
    "    },\n",
    "    KNeighborsClassifier(): {\n",
    "        \"n_neighbors\": [3, 5, 10, 20],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    },\n",
    "    # SVC(): {\n",
    "    #     \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    #     \"C\": [0.1, 1, 10, 100],\n",
    "    #     \"gamma\": [\"scale\", \"auto\"],\n",
    "    # },\n",
    "    DecisionTreeClassifier(): {\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 10, 20],\n",
    "        \"min_samples_leaf\": [1, 5, 10],\n",
    "    },\n",
    "    RandomForestClassifier(): {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "    },\n",
    "    GradientBoostingClassifier(): {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 5, 10],\n",
    "    },\n",
    "    AdaBoostClassifier(): {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 1.0],\n",
    "    },\n",
    "    GaussianNB(): {},\n",
    "    MultinomialNB(): {\"alpha\": [0.01, 0.1, 1, 10]},\n",
    "    BernoulliNB(): {\"alpha\": [0.01, 0.1, 1, 10]},\n",
    "    Perceptron(): {\n",
    "        \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "        \"max_iter\": [1000, 2000, 3000],\n",
    "    },\n",
    "    SGDClassifier(): {\n",
    "        \"loss\": [\"hinge\", \"log\", \"modified_huber\"],\n",
    "        \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "        \"learning_rate\": [\"constant\", \"optimal\", \"invscaling\", \"adaptive\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "models_and_params = models_params.items()\n",
    "n_models = len(models_and_params)\n",
    "current_model_iter = 1\n",
    "\n",
    "for model, params in models_and_params:\n",
    "    model_name = model.__class__.__name__\n",
    "    print(f\"Avaliando o modelo {model_name}... [{current_model_iter}/{n_models}]\")\n",
    "    try:\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5)\n",
    "        grid_search.fit(X_train, Y_train)\n",
    "        test_score = grid_search.score(X_test, Y_test)\n",
    "        results.append(\n",
    "            {\n",
    "                \"Modelo\": model_name,\n",
    "                \"Melhor pontuação\": grid_search.best_score_,\n",
    "                \"Melhores parâmetros\": grid_search.best_params_,\n",
    "                \"Resultado avaliação\": test_score,\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no modelo {model.__class__.__name__}\")\n",
    "    current_model_iter += 1\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('../data/out/resultado_gs_classificacao.csv', index=False)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
