{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atuação de redes neurais na base de dados do ENEM.\n",
    "\n",
    "##### Alunos:\n",
    "\n",
    "-   Gabriel Fonseca (2111066)\n",
    "-   Yasmim Santos (2116925)\n",
    "-   Alejandro Elias (2111189)\n",
    "-   Pedro Lucas (2111131)\n",
    "\n",
    "Base de dados escolhida - Exame Nacional do Ensino Médio (Enem): https://basedosdados.org/dataset/3e9c8804-c31c-4f48-9a45-d67f1c21a859\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>pc11</th>\n",
       "      <th>pc12</th>\n",
       "      <th>pc13</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080772</td>\n",
       "      <td>-0.762073</td>\n",
       "      <td>0.785344</td>\n",
       "      <td>-0.199764</td>\n",
       "      <td>-0.054483</td>\n",
       "      <td>0.049965</td>\n",
       "      <td>0.085057</td>\n",
       "      <td>-0.540182</td>\n",
       "      <td>0.122058</td>\n",
       "      <td>-0.009384</td>\n",
       "      <td>-0.204944</td>\n",
       "      <td>0.117868</td>\n",
       "      <td>0.051204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.393375</td>\n",
       "      <td>-0.548347</td>\n",
       "      <td>0.338718</td>\n",
       "      <td>0.221928</td>\n",
       "      <td>0.016524</td>\n",
       "      <td>-0.173460</td>\n",
       "      <td>-0.307259</td>\n",
       "      <td>-0.246581</td>\n",
       "      <td>-0.040625</td>\n",
       "      <td>-0.236048</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>0.149297</td>\n",
       "      <td>-0.062338</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776151</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>-0.138433</td>\n",
       "      <td>-0.401180</td>\n",
       "      <td>-0.118839</td>\n",
       "      <td>0.141531</td>\n",
       "      <td>0.238757</td>\n",
       "      <td>-0.504716</td>\n",
       "      <td>0.119788</td>\n",
       "      <td>-0.021916</td>\n",
       "      <td>-0.216930</td>\n",
       "      <td>0.090747</td>\n",
       "      <td>0.061515</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.298045</td>\n",
       "      <td>-0.212122</td>\n",
       "      <td>-0.284790</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>-0.069669</td>\n",
       "      <td>-0.025346</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>-0.003425</td>\n",
       "      <td>0.037167</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>-0.047331</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.112868</td>\n",
       "      <td>-0.191347</td>\n",
       "      <td>-0.089860</td>\n",
       "      <td>0.090623</td>\n",
       "      <td>-0.013232</td>\n",
       "      <td>-0.043385</td>\n",
       "      <td>0.032071</td>\n",
       "      <td>0.104206</td>\n",
       "      <td>0.030562</td>\n",
       "      <td>0.156052</td>\n",
       "      <td>0.022517</td>\n",
       "      <td>-0.053376</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176574</th>\n",
       "      <td>0.690036</td>\n",
       "      <td>0.275459</td>\n",
       "      <td>-0.179739</td>\n",
       "      <td>0.192360</td>\n",
       "      <td>0.070063</td>\n",
       "      <td>-0.119760</td>\n",
       "      <td>-0.097103</td>\n",
       "      <td>-0.064441</td>\n",
       "      <td>0.026953</td>\n",
       "      <td>-0.002614</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>0.109682</td>\n",
       "      <td>-0.017169</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176575</th>\n",
       "      <td>-0.864843</td>\n",
       "      <td>0.316883</td>\n",
       "      <td>-0.248853</td>\n",
       "      <td>-0.297550</td>\n",
       "      <td>-0.790818</td>\n",
       "      <td>-0.036361</td>\n",
       "      <td>-0.041141</td>\n",
       "      <td>-0.010166</td>\n",
       "      <td>0.254156</td>\n",
       "      <td>-0.300570</td>\n",
       "      <td>-0.073253</td>\n",
       "      <td>-0.256313</td>\n",
       "      <td>-0.678971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176576</th>\n",
       "      <td>-0.690970</td>\n",
       "      <td>-0.464787</td>\n",
       "      <td>-0.921498</td>\n",
       "      <td>-0.172432</td>\n",
       "      <td>-0.288687</td>\n",
       "      <td>-0.029190</td>\n",
       "      <td>-0.171915</td>\n",
       "      <td>-0.371058</td>\n",
       "      <td>-0.857355</td>\n",
       "      <td>0.223508</td>\n",
       "      <td>-0.043842</td>\n",
       "      <td>0.255755</td>\n",
       "      <td>0.332502</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176577</th>\n",
       "      <td>-0.095767</td>\n",
       "      <td>-0.509823</td>\n",
       "      <td>0.567619</td>\n",
       "      <td>0.561381</td>\n",
       "      <td>0.035622</td>\n",
       "      <td>-0.666075</td>\n",
       "      <td>-0.746409</td>\n",
       "      <td>-0.182901</td>\n",
       "      <td>0.341742</td>\n",
       "      <td>0.691724</td>\n",
       "      <td>-0.216121</td>\n",
       "      <td>-0.045788</td>\n",
       "      <td>0.065079</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176578</th>\n",
       "      <td>0.814776</td>\n",
       "      <td>-0.243723</td>\n",
       "      <td>-0.261948</td>\n",
       "      <td>-0.970291</td>\n",
       "      <td>-0.086218</td>\n",
       "      <td>0.096915</td>\n",
       "      <td>-0.035954</td>\n",
       "      <td>-0.058765</td>\n",
       "      <td>-0.113806</td>\n",
       "      <td>-0.304762</td>\n",
       "      <td>-0.017130</td>\n",
       "      <td>-0.015052</td>\n",
       "      <td>-0.018150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176579 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0       0.080772 -0.762073  0.785344 -0.199764 -0.054483  0.049965  0.085057   \n",
       "1      -0.393375 -0.548347  0.338718  0.221928  0.016524 -0.173460 -0.307259   \n",
       "2       0.776151  0.015068 -0.138433 -0.401180 -0.118839  0.141531  0.238757   \n",
       "3      -0.298045 -0.212122 -0.284790  0.008414 -0.069669 -0.025346  0.005120   \n",
       "4      -0.112868 -0.191347 -0.089860  0.090623 -0.013232 -0.043385  0.032071   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "176574  0.690036  0.275459 -0.179739  0.192360  0.070063 -0.119760 -0.097103   \n",
       "176575 -0.864843  0.316883 -0.248853 -0.297550 -0.790818 -0.036361 -0.041141   \n",
       "176576 -0.690970 -0.464787 -0.921498 -0.172432 -0.288687 -0.029190 -0.171915   \n",
       "176577 -0.095767 -0.509823  0.567619  0.561381  0.035622 -0.666075 -0.746409   \n",
       "176578  0.814776 -0.243723 -0.261948 -0.970291 -0.086218  0.096915 -0.035954   \n",
       "\n",
       "             pc8       pc9      pc10      pc11      pc12      pc13  label  \n",
       "0      -0.540182  0.122058 -0.009384 -0.204944  0.117868  0.051204      0  \n",
       "1      -0.246581 -0.040625 -0.236048  0.013179  0.149297 -0.062338      3  \n",
       "2      -0.504716  0.119788 -0.021916 -0.216930  0.090747  0.061515      2  \n",
       "3       0.034136 -0.003425  0.037167  0.015733 -0.047331 -0.001086      4  \n",
       "4       0.104206  0.030562  0.156052  0.022517 -0.053376  0.016360      3  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "176574 -0.064441  0.026953 -0.002614  0.016944  0.109682 -0.017169      2  \n",
       "176575 -0.010166  0.254156 -0.300570 -0.073253 -0.256313 -0.678971      1  \n",
       "176576 -0.371058 -0.857355  0.223508 -0.043842  0.255755  0.332502      4  \n",
       "176577 -0.182901  0.341742  0.691724 -0.216121 -0.045788  0.065079      3  \n",
       "176578 -0.058765 -0.113806 -0.304762 -0.017130 -0.015052 -0.018150      2  \n",
       "\n",
       "[176579 rows x 14 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enem = pd.read_csv(\"../data/out/enem-dados-tratados-ml.csv\")\n",
    "\n",
    "tts_r_state = 73\n",
    "mlp_r_state = 83\n",
    "\n",
    "X = df_enem.drop(\"label\", axis=1).to_numpy()\n",
    "y = df_enem[\"label\"]\n",
    "\n",
    "num_classes = len(y.unique())\n",
    "\n",
    "y = y.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=tts_r_state\n",
    ")\n",
    "\n",
    "n_components = X.shape[1]\n",
    "\n",
    "y_train_keras = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_keras = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "df_enem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ~~Diminuir o número de epocas~~\n",
    "2. ~~Variar o batch size~~\n",
    "3. ~~Testar outro modelo sem ser de deep learning~~\n",
    "4. ~~Testar a variação das camadas ocultas utilizando tensorflow e colocando a função de ativação softmax na camada de saida~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_grid_search(\n",
    "    model: BaseEstimator,\n",
    "    param_grid: dict,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    n_components: int,\n",
    "):\n",
    "    model_name = model.__class__.__name__.lower()\n",
    "\n",
    "    grid_search = GridSearchCV(model, param_grid, n_jobs=-1, cv=5, scoring=\"accuracy\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    resultado_gs = pd.DataFrame(grid_search.cv_results_)\n",
    "    resultado_gs = resultado_gs.sort_values(by=\"rank_test_score\")\n",
    "\n",
    "    resultado_gs.to_csv(\n",
    "        f\"../data/out/resultado_gridsearch_{model_name}_{n_components}.csv\", index=False\n",
    "    )\n",
    "\n",
    "    resultado_gs = resultado_gs[\n",
    "        [\"params\", \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "    ]\n",
    "\n",
    "    return resultado_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 863us/step - accuracy: 0.9376 - loss: 0.2565 - val_accuracy: 0.9972 - val_loss: 0.0077\n",
      "Epoch 2/10\n",
      "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 835us/step - accuracy: 0.9972 - loss: 0.0062 - val_accuracy: 0.9961 - val_loss: 0.0104\n",
      "Epoch 3/10\n",
      "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 789us/step - accuracy: 0.9982 - loss: 0.0047 - val_accuracy: 0.9977 - val_loss: 0.0047\n",
      "Epoch 4/10\n",
      "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 798us/step - accuracy: 0.9982 - loss: 0.0040 - val_accuracy: 0.9976 - val_loss: 0.0057\n",
      "Epoch 5/10\n",
      "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 814us/step - accuracy: 0.9980 - loss: 0.0049 - val_accuracy: 0.9978 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 809us/step - accuracy: 0.9988 - loss: 0.0032 - val_accuracy: 0.9978 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 799us/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.9976 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 860us/step - accuracy: 0.9985 - loss: 0.0036 - val_accuracy: 0.9989 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 800us/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9988 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 788us/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.9981 - val_loss: 0.0045\n",
      "\u001b[1m2760/2760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 540us/step - accuracy: 0.9986 - loss: 0.0033\n",
      "Test accuracy: 0.9986295104026794\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(5, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    X_train, y_train_keras, epochs=10, batch_size=32, validation_split=0.2\n",
    ")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_keras)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>{'alpha': 0.0001, 'early_stopping': False, 'et...</td>\n",
       "      <td>0.997021</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>{'alpha': 0.001, 'early_stopping': False, 'eta...</td>\n",
       "      <td>0.997021</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6915</th>\n",
       "      <td>{'alpha': 0.01, 'early_stopping': False, 'eta0...</td>\n",
       "      <td>0.997021</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>{'alpha': 0.001, 'early_stopping': False, 'eta...</td>\n",
       "      <td>0.997021</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>{'alpha': 0.001, 'early_stopping': False, 'eta...</td>\n",
       "      <td>0.997021</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9188</th>\n",
       "      <td>{'alpha': 0.1, 'early_stopping': False, 'eta0'...</td>\n",
       "      <td>0.175140</td>\n",
       "      <td>0.086448</td>\n",
       "      <td>10360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>{'alpha': 0.1, 'early_stopping': False, 'eta0'...</td>\n",
       "      <td>0.175140</td>\n",
       "      <td>0.086448</td>\n",
       "      <td>10360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>{'alpha': 0.1, 'early_stopping': False, 'eta0'...</td>\n",
       "      <td>0.175140</td>\n",
       "      <td>0.086448</td>\n",
       "      <td>10360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9258</th>\n",
       "      <td>{'alpha': 0.1, 'early_stopping': False, 'eta0'...</td>\n",
       "      <td>0.175140</td>\n",
       "      <td>0.086448</td>\n",
       "      <td>10360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9187</th>\n",
       "      <td>{'alpha': 0.1, 'early_stopping': False, 'eta0'...</td>\n",
       "      <td>0.175140</td>\n",
       "      <td>0.086448</td>\n",
       "      <td>10360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10368 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 params  mean_test_score  \\\n",
       "1296  {'alpha': 0.0001, 'early_stopping': False, 'et...         0.997021   \n",
       "4325  {'alpha': 0.001, 'early_stopping': False, 'eta...         0.997021   \n",
       "6915  {'alpha': 0.01, 'early_stopping': False, 'eta0...         0.997021   \n",
       "4395  {'alpha': 0.001, 'early_stopping': False, 'eta...         0.997021   \n",
       "4396  {'alpha': 0.001, 'early_stopping': False, 'eta...         0.997021   \n",
       "...                                                 ...              ...   \n",
       "9188  {'alpha': 0.1, 'early_stopping': False, 'eta0'...         0.175140   \n",
       "9115  {'alpha': 0.1, 'early_stopping': False, 'eta0'...         0.175140   \n",
       "9116  {'alpha': 0.1, 'early_stopping': False, 'eta0'...         0.175140   \n",
       "9258  {'alpha': 0.1, 'early_stopping': False, 'eta0'...         0.175140   \n",
       "9187  {'alpha': 0.1, 'early_stopping': False, 'eta0'...         0.175140   \n",
       "\n",
       "      std_test_score  rank_test_score  \n",
       "1296        0.000380                1  \n",
       "4325        0.000380                1  \n",
       "6915        0.000380                1  \n",
       "4395        0.000380                1  \n",
       "4396        0.000380                1  \n",
       "...              ...              ...  \n",
       "9188        0.086448            10360  \n",
       "9115        0.086448            10360  \n",
       "9116        0.086448            10360  \n",
       "9258        0.086448            10360  \n",
       "9187        0.086448            10360  \n",
       "\n",
       "[10368 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron(random_state=mlp_r_state)\n",
    "\n",
    "param_grid = {\n",
    "    \"penalty\": [None, \"l2\", \"l1\", \"elasticnet\"],\n",
    "    \"alpha\": [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"max_iter\": [1000, 2000, 3000],\n",
    "    \"tol\": [1e-3, 1e-4, 1e-5],\n",
    "    \"shuffle\": [True, False],\n",
    "    \"eta0\": [1.0, 0.1, 0.01],\n",
    "    \"early_stopping\": [True, False],\n",
    "    \"validation_fraction\": [0.1, 0.2, 0.3],\n",
    "}\n",
    "\n",
    "class_grid_search(perceptron, param_grid, X_train, y_train, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.999241</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'batch_...</td>\n",
       "      <td>0.998403</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'batch_...</td>\n",
       "      <td>0.998403</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'batch_...</td>\n",
       "      <td>0.998403</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'batch_...</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.001, 'batch_...</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  mean_test_score  \\\n",
       "42   {'activation': 'tanh', 'alpha': 0.0001, 'batch...         0.999298   \n",
       "45   {'activation': 'tanh', 'alpha': 0.0001, 'batch...         0.999298   \n",
       "147  {'activation': 'relu', 'alpha': 0.0001, 'batch...         0.999241   \n",
       "144  {'activation': 'relu', 'alpha': 0.0001, 'batch...         0.999241   \n",
       "150  {'activation': 'relu', 'alpha': 0.0001, 'batch...         0.999241   \n",
       "..                                                 ...              ...   \n",
       "65   {'activation': 'tanh', 'alpha': 0.001, 'batch_...         0.998403   \n",
       "64   {'activation': 'tanh', 'alpha': 0.001, 'batch_...         0.998403   \n",
       "62   {'activation': 'tanh', 'alpha': 0.001, 'batch_...         0.998403   \n",
       "63   {'activation': 'tanh', 'alpha': 0.001, 'batch_...         0.998380   \n",
       "60   {'activation': 'tanh', 'alpha': 0.001, 'batch_...         0.998380   \n",
       "\n",
       "     std_test_score  rank_test_score  \n",
       "42         0.000198                1  \n",
       "45         0.000198                1  \n",
       "147        0.000337                3  \n",
       "144        0.000337                3  \n",
       "150        0.000185                5  \n",
       "..              ...              ...  \n",
       "65         0.000241              211  \n",
       "64         0.000241              211  \n",
       "62         0.000241              211  \n",
       "63         0.000223              215  \n",
       "60         0.000223              215  \n",
       "\n",
       "[216 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=mlp_r_state)\n",
    "\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "    \"activation\": [\"tanh\", \"relu\"],\n",
    "    \"solver\": [\"adam\"],\n",
    "    \"alpha\": [1e-4, 1e-3],\n",
    "    \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"max_iter\": [30, 60, 90],\n",
    "}\n",
    "\n",
    "class_grid_search(mlp, param_grid, X_train, y_train, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9016309887869521"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_params = {\n",
    "    \"alpha\": 0.0001,\n",
    "    \"early_stopping\": False,\n",
    "    \"eta0\": 0.1,\n",
    "    \"fit_intercept\": False,\n",
    "    \"max_iter\": 3000,\n",
    "    \"penalty\": \"l1\",\n",
    "    \"shuffle\": True,\n",
    "    \"tol\": 1e-05,\n",
    "    \"validation_fraction\": 0.3,\n",
    "}\n",
    "\n",
    "perceptron = Perceptron(**perceptron_params)\n",
    "\n",
    "perceptron.fit(X_train, y_train)\n",
    "test_accuracy = perceptron.score(X_test, y_test)\n",
    "\n",
    "test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
